import tradingview_screener as tvs
import pandas as pd
import numpy as np
from scipy import stats
import akshare as ak
import time
import glob
import json


def focused_fcf_turnover_screener():
    """
    ä¸“æ³¨è‡ªç”±ç°é‡‘æµè¾¹é™…å’Œèµ„äº§å‘¨è½¬ç‡çš„é€‰è‚¡å™¨
    å…¶ä»–æŒ‡æ ‡ç”¨äºéªŒè¯ç›ˆåˆ©è´¨é‡å’Œä¼°å€¼åˆç†æ€§
    """

    # è·å–æ•°æ®
    broad_query = (tvs.Query()
        .set_markets('china')
        .select(
            'name', 'description', 'market_cap_basic',
            # æ ¸å¿ƒæŒ‡æ ‡
            'free_cash_flow_margin_ttm',
            'asset_turnover_current',
            # ç›ˆåˆ©è´¨é‡éªŒè¯
            'net_income_ttm', 'operating_margin', 'gross_margin',
            'return_on_equity', 'return_on_assets',
            # å¢é•¿éªŒè¯
            'total_revenue_yoy_growth_ttm', 'net_income_yoy_growth_ttm',
            'free_cash_flow_yoy_growth_ttm',
            # è´¢åŠ¡å¥åº·éªŒè¯
            'debt_to_equity', 'current_ratio', 'quick_ratio',
            # ä¼°å€¼éªŒè¯
            'price_earnings_ttm', 'price_book_ratio', 'price_sales_ratio',
            'price_earnings_growth_ttm',  # PEGæŒ‡æ ‡
            # æŠ€æœ¯æŒ‡æ ‡
            'Recommend.All', 'Recommend.All|1W',
            'Recommend.MA', 'Recommend.MA|1W',
            'Recommend.Other', 'Recommend.Other|1W',
            # åŸºæœ¬ä¿¡æ¯
            'sector', 'industry', 'exchange', 'close', 'volume'
        )
        .where(
            tvs.col('type') == 'stock',
            tvs.col('market_cap_basic') > 1000000000,  # å¸‚å€¼ > 10äº¿
            tvs.col('total_revenue_ttm') > 0,  # æœ‰è¥ä¸šæ”¶å…¥
            tvs.col('net_income_ttm') > 0  # å‡€åˆ©æ¶¦ä¸ºæ­£
        )
        .limit(3000)
    )

    broad_count, broad_data = broad_query.get_scanner_data()

    if broad_data.empty:
        print("æœªè·å–åˆ°è¶³å¤Ÿæ•°æ®è¿›è¡Œè¡Œä¸šåˆ†æ")
        return 0, pd.DataFrame()

    # è¡Œä¸šæ ‡å‡†åŒ–å‡½æ•°
    def industry_normalization(df, metrics):
        normalized_df = df.copy()

        for sector in df['sector'].unique():
            sector_mask = df['sector'] == sector
            sector_data = df[sector_mask]

            for metric in metrics:
                if metric in df.columns:
                    sector_values = sector_data[metric].dropna()
                    if len(sector_values) > 5:
                        normalized_df.loc[sector_mask, f'{metric}_industry_rank'] = (
                            sector_data[metric].rank(pct=True) * 100
                        )
                    else:
                        normalized_df.loc[sector_mask, f'{metric}_industry_rank'] = (
                            df[metric].rank(pct=True) * 100
                        )

        return normalized_df

    # æ ¸å¿ƒæŒ‡æ ‡ + éªŒè¯æŒ‡æ ‡
    key_metrics = [
        # æ ¸å¿ƒæŒ‡æ ‡
        'free_cash_flow_margin_ttm',
        'asset_turnover_current',
        # ç›ˆåˆ©è´¨é‡éªŒè¯
        'operating_margin',
        'return_on_equity',
        # å¢é•¿éªŒè¯
        'total_revenue_yoy_growth_ttm',
        'net_income_yoy_growth_ttm',
        # è´¢åŠ¡å¥åº·éªŒè¯
        'debt_to_equity',
        # ä¼°å€¼éªŒè¯
        'price_earnings_ttm',
        'price_earnings_growth_ttm'  # PEG
    ]

    # åº”ç”¨è¡Œä¸šæ ‡å‡†åŒ–
    normalized_data = industry_normalization(broad_data, key_metrics)

    def calculate_focused_score(row):
        """
        ä¸“æ³¨FCFè¾¹é™…å’Œèµ„äº§å‘¨è½¬ç‡çš„è¯„åˆ†ä½“ç³»
        """
        score = 0

        try:
            # ğŸ¯ æ ¸å¿ƒç­–ç•¥æŒ‡æ ‡ - 70%æƒé‡
            # FCFè¾¹é™…è¡Œä¸šæ’å (35%)
            fcf_rank = row.get('free_cash_flow_margin_ttm_industry_rank', 0)
            score += min(fcf_rank * 0.35, 35)

            # èµ„äº§å‘¨è½¬ç‡è¡Œä¸šæ’å (35%)
            turnover_rank = row.get('asset_turnover_current_industry_rank', 0)
            score += min(turnover_rank * 0.35, 35)

            # âœ… ç›ˆåˆ©è´¨é‡éªŒè¯ - 15%æƒé‡
            # è¿è¥åˆ©æ¶¦ç‡è¡Œä¸šæ’å (10%)
            op_margin_rank = row.get('operating_margin_industry_rank', 0)
            score += min(op_margin_rank * 0.10, 10)

            # ROEè¡Œä¸šæ’å (5%)
            roe_rank = row.get('return_on_equity_industry_rank', 0)
            score += min(roe_rank * 0.05, 5)

            # ğŸ“ˆ å¢é•¿éªŒè¯ - 10%æƒé‡
            # æ”¶å…¥å¢é•¿è¡Œä¸šæ’å (5%)
            revenue_growth_rank = row.get('total_revenue_yoy_growth_ttm_industry_rank', 0)
            score += min(revenue_growth_rank * 0.05, 5)

            # å‡€åˆ©æ¶¦å¢é•¿è¡Œä¸šæ’å (5%)
            net_income_growth_rank = row.get('net_income_yoy_growth_ttm_industry_rank', 0)
            score += min(net_income_growth_rank * 0.05, 5)

            # ğŸ’° ä¼°å€¼åˆç†æ€§éªŒè¯ - 5%æƒé‡
            # PEGè¡Œä¸šæ’å (åå‘æŒ‡æ ‡ï¼Œè¶Šä½è¶Šå¥½)
            if pd.notna(row.get('price_earnings_growth_ttm_industry_rank')):
                peg_rank = row['price_earnings_growth_ttm_industry_rank']
                # PEG < 1 é€šå¸¸è¢«è®¤ä¸ºæ˜¯åˆç†çš„
                if row.get('price_earnings_growth_ttm', 999) < 1.5:
                    score += 5
                elif row.get('price_earnings_growth_ttm', 999) < 2:
                    score += 3
                else:
                    score += 1
            else:
                # å¦‚æœæ²¡æœ‰PEGæ•°æ®ï¼Œç”¨PEåˆ¤æ–­
                pe_rank = row.get('price_earnings_ttm_industry_rank', 50)
                pe_score = max(0, (100 - pe_rank) * 0.05)  # PEè¶Šä½è¶Šå¥½
                score += min(pe_score, 5)

        except (ValueError, TypeError):
            return 0

        return min(score, 100)

    # åº”ç”¨ä¸“æ³¨è¯„åˆ†
    normalized_data['focused_fcf_turnover_score'] = normalized_data.apply(
        calculate_focused_score, axis=1
    )

    # è®¡ç®—æ ¸å¿ƒç»„åˆæŒ‡æ ‡
    normalized_data['fcf_turnover_composite'] = (
        normalized_data['free_cash_flow_margin_ttm_industry_rank'] * 0.6 +
        normalized_data['asset_turnover_current_industry_rank'] * 0.4
    )

    # éªŒè¯æŒ‡æ ‡ç»„åˆ
    def calculate_validation_score(row):
        """è®¡ç®—éªŒè¯æŒ‡æ ‡å¾—åˆ†ï¼Œç”¨äºç¡®è®¤ç›ˆåˆ©è´¨é‡å’Œä¼°å€¼"""
        validation_score = 0

        # ç›ˆåˆ©è´¨é‡éªŒè¯ (60%)
        op_margin_rank = row.get('operating_margin_industry_rank', 0)
        roe_rank = row.get('return_on_equity_industry_rank', 0)
        revenue_growth_rank = row.get('total_revenue_yoy_growth_ttm_industry_rank', 0)

        profitability_quality = (op_margin_rank + roe_rank + revenue_growth_rank) / 3
        validation_score += profitability_quality * 0.6

        # è´¢åŠ¡å¥åº·éªŒè¯ (20%)
        debt_rank = row.get('debt_to_equity_industry_rank', 50)
        financial_health = (100 - debt_rank)  # è´Ÿå€ºè¶Šä½è¶Šå¥½
        validation_score += financial_health * 0.2

        # ä¼°å€¼éªŒè¯ (20%)
        if pd.notna(row.get('price_earnings_growth_ttm')):
            peg = row['price_earnings_growth_ttm']
            if peg < 1:
                valuation_score = 100
            elif peg < 1.5:
                valuation_score = 80
            elif peg < 2:
                valuation_score = 60
            else:
                valuation_score = 40
        else:
            pe_rank = row.get('price_earnings_ttm_industry_rank', 50)
            valuation_score = 100 - pe_rank  # PEè¶Šä½è¶Šå¥½

        validation_score += valuation_score * 0.2

        return min(validation_score, 100)

    normalized_data['validation_score'] = normalized_data.apply(
        calculate_validation_score, axis=1
    )

    # ğŸ¯ æœ€ç»ˆç­›é€‰æ¡ä»¶ - æ›´åŠ ä¸“æ³¨æ ¸å¿ƒæŒ‡æ ‡
    screening_criteria = (
        (normalized_data['focused_fcf_turnover_score'] >= 70) &  # æ ¸å¿ƒè¯„åˆ† >= 70
        (normalized_data['fcf_turnover_composite'] >= 70) &  # FCFå‘¨è½¬ç»„åˆæ’åå‰30%
        (normalized_data['validation_score'] >= 60) &  # éªŒè¯è¯„åˆ†åŠæ ¼
        (normalized_data['market_cap_basic'] > 5000000000) &  # å¸‚å€¼ > 50äº¿
        (normalized_data['free_cash_flow_margin_ttm'] > 0.05) &  # FCFè¾¹é™… > 5%
        (normalized_data['asset_turnover_current'] > 0.2) &  # èµ„äº§å‘¨è½¬ç‡ > 0.2
        (normalized_data['net_income_yoy_growth_ttm'] > 0) &  # å‡€åˆ©æ¶¦å¢é•¿ä¸ºæ­£
        (normalized_data['total_revenue_yoy_growth_ttm'] > 0)  # æ”¶å…¥å¢é•¿ä¸ºæ­£
    )

    screened_stocks = normalized_data[screening_criteria].copy()

    if screened_stocks.empty:
        print("æœªæ‰¾åˆ°ç¬¦åˆæ ¸å¿ƒç­–ç•¥çš„ä¼˜è´¨è‚¡ç¥¨")
        return 0, pd.DataFrame()

    # æŒ‰æ ¸å¿ƒè¯„åˆ†å’ŒFCFå‘¨è½¬ç»„åˆæ’åº
    screened_stocks = screened_stocks.sort_values(
        by=['focused_fcf_turnover_score', 'fcf_turnover_composite'],
        ascending=[False, False]
    )

    # æ·»åŠ æŠ•èµ„é€»è¾‘æ ‡ç­¾
    def get_investment_rationale(row):
        rationale = []

        fcf_margin_rank = row.get('free_cash_flow_margin_ttm_industry_rank', 0)
        turnover_rank = row.get('asset_turnover_current_industry_rank', 0)
        fcf_turnover_composite = row.get('fcf_turnover_composite', 0)
        peg = row.get('price_earnings_growth_ttm', 999)
        net_income_growth = row.get('net_income_yoy_growth_ttm', 0)

        if fcf_margin_rank >= 80:
            rationale.append("åˆ©æ¶¦ç‡é¢†å…ˆ")
        elif fcf_margin_rank >= 60:
            rationale.append("åˆ©æ¶¦ç‡ä¼˜ç§€")

        if turnover_rank >= 80:
            rationale.append("èµ„äº§å‘¨è½¬é¢†å…ˆ")
        elif turnover_rank >= 60:
            rationale.append("èµ„äº§å‘¨è½¬ä¼˜ç§€")

        if fcf_turnover_composite >= 80:
            rationale.append("ç°é‡‘æµå›æŠ¥é¢†å…ˆ")
        elif fcf_turnover_composite >= 60:
            rationale.append("ç°é‡‘æµå›æŠ¥ä¼˜ç§€")

        if peg < 1:
            rationale.append("å¸‚ç›ˆå¢é•¿ç‡æå…·å¸å¼•åŠ›")
        elif peg < 1.5:
            rationale.append("å¸‚ç›ˆå¢é•¿ç‡åˆç†")

        if net_income_growth > 0.2:
            rationale.append("é«˜ç›ˆåˆ©å¢é•¿")
        elif net_income_growth > 0.1:
            rationale.append("ç¨³å¥ç›ˆåˆ©å¢é•¿")

        return " | ".join(rationale) if rationale else "ç¬¦åˆåŸºç¡€æ ‡å‡†"

    screened_stocks['investment_rationale'] = screened_stocks.apply(
        get_investment_rationale, axis=1
    )

    # é€‰æ‹©è¾“å‡ºåˆ— - æ›´åŠ ä¸“æ³¨æ ¸å¿ƒæŒ‡æ ‡
    output_columns = [
        'name', 'description', 'sector', 'industry', 'close', 'market_cap_basic',
        'focused_fcf_turnover_score', 'validation_score', 'investment_rationale',
        # æ ¸å¿ƒæŒ‡æ ‡
        'free_cash_flow_margin_ttm', 'free_cash_flow_margin_ttm_industry_rank',
        'asset_turnover_current', 'asset_turnover_current_industry_rank',
        'fcf_turnover_composite',
        # å…³é”®éªŒè¯æŒ‡æ ‡
        'operating_margin', 'return_on_equity',
        'net_income_yoy_growth_ttm', 'total_revenue_yoy_growth_ttm',
        'price_earnings_growth_ttm', 'debt_to_equity',
        # æŠ€æœ¯æŒ‡æ ‡
        'Recommend.All', 'Recommend.All|1W',
        'Recommend.MA', 'Recommend.MA|1W',
        'Recommend.Other', 'Recommend.Other|1W',
        'exchange'
    ]

    final_df = screened_stocks[output_columns]

    # åˆ†æç»“æœ
    print(f"ğŸ¯ æ‰¾åˆ° {len(final_df)} åªç¬¦åˆFCFå‘¨è½¬ç­–ç•¥çš„ä¸­å›½è‚¡ç¥¨")
    print("\nğŸ“Š æ ¸å¿ƒç­›é€‰æ ‡å‡†:")
    print("- FCFè¾¹é™…è¡Œä¸šæ’å + èµ„äº§å‘¨è½¬ç‡è¡Œä¸šæ’å (70%æƒé‡)")
    print("- ç›ˆåˆ©è´¨é‡å’Œä¼°å€¼éªŒè¯ (30%æƒé‡)")
    print("- FCFè¾¹é™… > 5%, èµ„äº§å‘¨è½¬ç‡ > 0.2")
    print("- æ”¶å…¥å’Œå‡€åˆ©æ¶¦å¢é•¿ä¸ºæ­£")
    print("- å¸‚å€¼ > 50äº¿äººæ°‘å¸")

    return len(final_df), final_df


def load_comment_data():
    """åŠ è½½ä¸œæ–¹è´¢å¯Œç½‘åƒè‚¡åƒè¯„æ•°æ®"""
    pattern = r"stock_data/stock_comment_em_*.parquet"
    files = glob.glob(pattern)

    if files:
        # Sort files by timestamp in filename
        files.sort(key=lambda x: x.split('_')[-1].replace('.parquet', ''))
        latest_file = files[-1]
        stock_comment_em_df = pd.read_parquet(latest_file)
        print(f"Loaded latest comment data from {latest_file}")
    else:
        print("No existing comment data files found. Fetching new data...")
        # è·å–ä¸œæ–¹è´¢å¯Œç½‘-åƒè‚¡åƒè¯„
        stock_comment_em_df = ak.stock_comment_em()

        # ä¿å­˜åƒè‚¡åƒè¯„æ•°æ®åˆ°æœ¬åœ°parquetæ–‡ä»¶ï¼Œæ³¨æ˜æ—¶é—´æˆ³
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        stock_comment_em_df = stock_comment_em_df.sort_values(by='ç›®å‰æ’å')
        stock_comment_em_df.to_parquet(f"stock_comment_em_{timestamp}.parquet", index=False)
        print(f"Saved new comment data to stock_comment_em_{timestamp}.parquet")

    return stock_comment_em_df


def create_final_list():
    """ç”Ÿæˆæœ€ç»ˆè‚¡ç¥¨åˆ—è¡¨å¹¶ä¿å­˜ä¸ºparquetæ–‡ä»¶"""

    # æ‰§è¡Œé€‰è‚¡å™¨
    profitable_count, profitable_df = focused_fcf_turnover_screener()

    if profitable_count == 0:
        print("æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨")
        return pd.DataFrame()

    # æ ¼å¼åŒ–æ˜¾ç¤ºæ•°æ®
    display_columns = [
        'name', 'description', 'sector', 'focused_fcf_turnover_score', 'investment_rationale',
        'free_cash_flow_margin_ttm', 'free_cash_flow_margin_ttm_industry_rank',
        'asset_turnover_current', 'asset_turnover_current_industry_rank',
        'fcf_turnover_composite', 'price_earnings_growth_ttm', 'market_cap_basic',
        'Recommend.All', 'Recommend.All|1W',
        'Recommend.MA', 'Recommend.MA|1W',
        'Recommend.Other', 'Recommend.Other|1W'
    ]

    display_df = profitable_df[display_columns].round(2)

    # é‡å‘½ååˆ—ä»¥ä¾¿æ›´å¥½ç†è§£
    display_df = display_df.rename(columns={
        'free_cash_flow_margin_ttm': 'ç°é‡‘æµåˆ©æ¶¦ç‡',
        'free_cash_flow_margin_ttm_industry_rank': 'ç°é‡‘æµè¡Œä¸šæ’å',
        'asset_turnover_current': 'èµ„äº§å‘¨è½¬ç‡',
        'asset_turnover_current_industry_rank': 'èµ„äº§å‘¨è½¬ç‡è¡Œä¸šæ’å',
        'fcf_turnover_composite': 'ç°é‡‘æµå›æŠ¥ç‡ç»¼åˆå¾—åˆ†',
        'price_earnings_growth_ttm': 'å¸‚ç›ˆå¢é•¿æ¯”ç‡',
        'market_cap_basic': 'å¸‚å€¼ï¼ˆäº¿å…ƒï¼‰',
        'focused_fcf_turnover_score': 'åŸºæœ¬é¢è¯„åˆ†',
        'investment_rationale': 'æŠ•èµ„ç†ç”±',
        'Recommend.All': 'æŠ€æœ¯è¯„çº§(æ—¥)',
        'Recommend.All|1W': 'æŠ€æœ¯è¯„çº§(å‘¨)',
        'Recommend.MA': 'å‡çº¿è¯„çº§(æ—¥)',
        'Recommend.MA|1W': 'å‡çº¿è¯„çº§(å‘¨)',
        'Recommend.Other': 'éœ‡è¡æŒ‡æ ‡è¯„çº§(æ—¥)',
        'Recommend.Other|1W': 'éœ‡è¡æŒ‡æ ‡è¯„çº§(å‘¨)'
    })

    # å¸‚å€¼è½¬æ¢ä¸ºäº¿
    display_df['å¸‚å€¼ï¼ˆäº¿å…ƒï¼‰'] = (display_df['å¸‚å€¼ï¼ˆäº¿å…ƒï¼‰'] / 100000000).round(1)

    # åŠ è½½è¯„è®ºæ•°æ®
    stock_comment_em_df = load_comment_data()

    # åˆå¹¶æ•°æ®
    combined_df = display_df.merge(
        stock_comment_em_df[['ä»£ç ', 'åç§°','æœ€æ–°ä»·','ä¸»åŠ›æˆæœ¬', 'æ¢æ‰‹ç‡','æœºæ„å‚ä¸åº¦', 'ç»¼åˆå¾—åˆ†',
           'ä¸Šå‡', 'ç›®å‰æ’å', 'å…³æ³¨æŒ‡æ•°']].rename(columns={'ä»£ç ': 'name'}),
        on='name',
        how='left'
    )

    # æ˜ å°„è¡Œä¸šåˆ°ä¸­æ–‡
    with open('stock_data/sector_translations.json', 'r', encoding='utf-8') as f:
        sector_map = json.load(f)

    combined_df['è¡Œä¸š'] = combined_df['sector'].map(sector_map).fillna(combined_df['sector'])
    combined_df['ä»£ç '] = combined_df['name']

    # è®¡ç®—æœ€ç»ˆç»„åˆæƒé‡
    combined_df['æƒé‡'] = combined_df['åŸºæœ¬é¢è¯„åˆ†'] * np.log(combined_df['å¸‚å€¼ï¼ˆäº¿å…ƒï¼‰'])
    combined_df['æƒé‡'] = combined_df['æƒé‡'] / combined_df['æƒé‡'].sum()

    # æ„å»ºæœ€ç»ˆåˆ—è¡¨
    final_columns = ['ä»£ç ','åç§°','è¡Œä¸š','åŸºæœ¬é¢è¯„åˆ†','æŠ•èµ„ç†ç”±',
           'å¸‚å€¼ï¼ˆäº¿å…ƒï¼‰','æœ€æ–°ä»·','ä¸»åŠ›æˆæœ¬', 'æ¢æ‰‹ç‡','æœºæ„å‚ä¸åº¦',
           'ä¸Šå‡', 'ç›®å‰æ’å', 'å…³æ³¨æŒ‡æ•°', 'æŠ€æœ¯è¯„çº§(æ—¥)', 'å‡çº¿è¯„çº§(æ—¥)', 'éœ‡è¡æŒ‡æ ‡è¯„çº§(æ—¥)',
           'æŠ€æœ¯è¯„çº§(å‘¨)', 'å‡çº¿è¯„çº§(å‘¨)', 'éœ‡è¡æŒ‡æ ‡è¯„çº§(å‘¨)', 'æƒé‡']

    final_list = combined_df[final_columns].sort_values(by='æƒé‡', ascending=False)

    # æ˜¾ç¤ºç»“æœæ‘˜è¦
    print("\n" + "="*100)
    print("FCFå‘¨è½¬ç­–ç•¥ä¼˜è´¨è‚¡ç¥¨æ¨è:")
    print("="*100)
    print(final_list.head(10).to_string(index=False))

    # ç­–ç•¥æ€»ç»“
    print(f"\nğŸ’¡ ç­–ç•¥æ€»ç»“:")
    print(f"- æ€»å…±æ‰¾åˆ° {len(final_list)} åªä¼˜è´¨è‚¡ç¥¨")
    print(f"- å¹³å‡åŸºæœ¬é¢è¯„åˆ†: {final_list['åŸºæœ¬é¢è¯„åˆ†'].mean():.1f}")
    print(f"- å¹³å‡å¸‚å€¼: {final_list['å¸‚å€¼ï¼ˆäº¿å…ƒï¼‰'].mean():.1f} äº¿å…ƒ")
    print(f"- è¡Œä¸šåˆ†å¸ƒ: {', '.join(final_list['è¡Œä¸š'].unique())}")

    # ä¿å­˜ä¸ºparquetæ–‡ä»¶
    timestamp = time.strftime("%Y%m%d_%H%M%S")
    filename = f"stock_data/cn_stock_screening_{timestamp}.parquet"
    final_list.to_parquet(filename, index=False)
    print(f"\nâœ… æœ€ç»ˆåˆ—è¡¨å·²ä¿å­˜åˆ°: {filename}")
    
    # åŒæ—¶ä¿å­˜ä¸ºJSONæ–‡ä»¶ä¾›ç½‘ç«™ä½¿ç”¨
    json_filename = f"stock_data/cn_stock_screening_{timestamp}.json"
    final_list.to_json(json_filename, orient='records', force_ascii=False, indent=2)
    print(f"âœ… JSONç‰ˆæœ¬å·²ä¿å­˜åˆ°: {json_filename}")

    return final_list


if __name__ == "__main__":
    # ç”Ÿæˆæœ€ç»ˆè‚¡ç¥¨åˆ—è¡¨
    final_list = create_final_list()

